

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Nestle &mdash; nestle 0.2.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=37f418d5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="examples/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            nestle
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="prior.html">The Prior Transform</a></li>
<li class="toctree-l1"><a class="reference internal" href="stopping.html">Stopping Criterion</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="devdocs.html">Developers’ Docs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">nestle</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Nestle</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="nestle">
<h1>Nestle<a class="headerlink" href="#nestle" title="Link to this heading"></a></h1>
<p>/ˈnesəl/ <em>(rhymes with “wrestle”)</em></p>
<a class="reference external image-reference" href="examples/plot_ellipsoids.html"><img alt="_images/sphx_glr_plot_ellipsoids_001.png" class="align-right" src="_images/sphx_glr_plot_ellipsoids_001.png" style="width: 280px;" />
</a>
<p>Pure Python, MIT-licensed implementation of nested sampling algorithms.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Nested_sampling_algorithm">Nested Sampling</a> is a
computational approach for integrating posterior probability in order
to compare models in Bayesian statistics. It is similar to Markov
Chain Monte Carlo (MCMC) in that it generates samples that can be used
to estimate the posterior probability distribution. Unlike MCMC, the
nature of the sampling also allows one to calculate the integral of
the distribution. It also happens to be a pretty good method for robustly
finding global maxima.</p>
<section id="install">
<h2>Install<a class="headerlink" href="#install" title="Link to this heading"></a></h2>
<p>Nestle depends on numpy and, optionally, scipy. Install with pip:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">nestle</span>
</pre></div>
</div>
<p>For the latest development version, see <a class="reference external" href="http://github.com/kbarbary/nestle">http://github.com/kbarbary/nestle</a>.</p>
</section>
<section id="getting-started">
<h2>Getting started<a class="headerlink" href="#getting-started" title="Link to this heading"></a></h2>
<p>The following is a simple but complete example of using Nestle to
sample the parameters of a line given three data points with
uncertainties:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">nestle</span>

<span class="n">data_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">data_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mf">4.1</span><span class="p">])</span>
<span class="n">data_yerr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>

<span class="c1"># Define a likelihood function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loglike</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">data_x</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">chisq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">data_y</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_yerr</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">chisq</span> <span class="o">/</span> <span class="mf">2.</span>

<span class="c1"># Define a function mapping the unit cube to the prior space.</span>
<span class="c1"># This function defines a flat prior in [-5., 5.) in both dimensions.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">prior_transform</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">10.0</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="mf">5.0</span>

<span class="c1"># Run nested sampling.</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nestle</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">loglike</span><span class="p">,</span> <span class="n">prior_transform</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">result</span><span class="o">.</span><span class="n">logz</span>     <span class="c1"># log evidence</span>
<span class="n">result</span><span class="o">.</span><span class="n">logzerr</span>  <span class="c1"># numerical (sampling) error on logz</span>
<span class="n">result</span><span class="o">.</span><span class="n">samples</span>  <span class="c1"># array of sample parameters</span>
<span class="n">result</span><span class="o">.</span><span class="n">weights</span>  <span class="c1"># array of weights associated with each sample</span>
</pre></div>
</div>
<ul class="simple">
<li><p>See <a class="reference internal" href="examples/index.html"><span class="doc">Examples</span></a> for more detailed examples.</p></li>
<li><p>See <a class="reference internal" href="prior.html"><span class="doc">The Prior Transform</span></a> for more information on the <code class="docutils literal notranslate"><span class="pre">prior_tranform</span></code> function.</p></li>
<li><p>See <a class="reference internal" href="stopping.html"><span class="doc">Stopping Criterion</span></a> for discussion on when the algorithm terminates.</p></li>
<li><p>See the <a class="reference internal" href="api.html"><span class="doc">API</span></a> page for detailed API documentation.</p></li>
</ul>
</section>
<section id="available-methods">
<h2>Available methods<a class="headerlink" href="#available-methods" title="Link to this heading"></a></h2>
<p>The trick in nested sampling is to, at each step in the algorithm,
<em>efficiently</em> choose a new point in parameter space drawn with
<em>uniform probability</em> from the parameter space with likelihood greater
than the current likelihood constraint. The different methods all use
the current set of active points as an indicator of where the target
parameter space lies, but differ in how they select new points from
it.</p>
<section id="mcmc-exploration-method-classic">
<h3>MCMC exploration (<code class="docutils literal notranslate"><span class="pre">method='classic'</span></code>)<a class="headerlink" href="#mcmc-exploration-method-classic" title="Link to this heading"></a></h3>
<p>This is close to the method described in Skilling (2004). A new point
is drawn by starting at a one of the existing active points and doing
a short MCMC walk away from the point, taking a fixed number of
steps. In the walk, a new point is accepted if it has likelihood
higher than the likelihood constraint; otherwise it is rejected. The
number of steps can be controlled with the <code class="docutils literal notranslate"><span class="pre">steps</span></code> parameter.</p>
</section>
<section id="single-ellipsoid-method-single">
<h3>Single ellipsoid (<code class="docutils literal notranslate"><span class="pre">method='single'</span></code>)<a class="headerlink" href="#single-ellipsoid-method-single" title="Link to this heading"></a></h3>
<p>This is the method described by Mukherjee, Parkinson &amp; Liddle (2006).
Determines a single ellipsoid that bounds all active points, enlarges
the ellipsoid by a user-settable factor, and selects a new point at
random from within the ellipsoid. The enlargement factor is designed
to ensure that the high-likelihood region is completely enclosed in
the ellipsoid.</p>
</section>
<section id="multiple-ellipsoids-method-multi">
<h3>Multiple ellipsoids (<code class="docutils literal notranslate"><span class="pre">method='multi'</span></code>)<a class="headerlink" href="#multiple-ellipsoids-method-multi" title="Link to this heading"></a></h3>
<p>This is the method first described in Shaw, Bridges &amp; Hobson (2007) and
implemented in the MultiNest software (Feroz, Hobson &amp; Bridges 2009).</p>
<p>In cases where the posterior is multi-modal, the single-ellipsoid
method can be extremely inefficient: In such situations, there are
clusters of active points on separate high-likelihood regions
separated by regions of lower likelihood.  Bounding all points in a
single ellipsoid means that the ellipsoid includes the
lower-likelihood regions we wish to avoid sampling from.</p>
<p>The solution is to detect these clusters and bound them in separate
ellipsoids.  For this, we use a recursive process where we perform
K-means clustering with K=2. If the resulting two ellipsoids have a
significantly lower total volume than the parent ellipsoid (less than
half), we accept the split and repeat the clustering and volume test
on each of the two subset of points. This process continues
recursively. Alternatively, if the total ellipse volume is
significantly greater than expected (based on the expected density of
points) this indicates that there may be more than two clusters and
that K=2 was not an appropriate cluster division. We therefore still
try to subdivide the clusters recursively. However, we still only
accept the final split into N clusters if the total volume decrease is
significant.</p>
</section>
</section>
<section id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="Link to this heading"></a></h2>
<p><strong>What potential biases are there in these methods?</strong></p>
<p>In all the nested sampling methods implemented here, there are
potential biases that can affect the resulting evidence and samples.
This is similar to the situation with traditional MCMC methods where
one needs to be aware of potential biases such as inadequate burn-in
and sample correlation. The nested sampling biases are perhaps even
more nefarious as they can be more difficult to detect. They are
particularly troublesome in high dimensional cases.</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">'classic'</span></code> method (MCMC exploration), the MCMC must run for
enough steps to adequately “forget” the point it started from, in
order for the final accepted point to be uniformly drawn from the
parameter space with likelihood higher than the constraint.
Particlurly for higher dimensional problems, you likely want to use a
value higher than the default of <code class="docutils literal notranslate"><span class="pre">steps=20</span></code>. It may be good to run
the sampling multiple times with different numbers of steps and check
that the results are consistent.</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">'single'</span></code>- and <code class="docutils literal notranslate"><span class="pre">'multi'</span></code>-ellipsoid methods, we are trying
to draw an ellipsoid or ellipsoids that completely contain the
iso-likelihood region; assuming we succeed in completely containing
it, we are unbiased and the efficiency is given by the ratio of the
volume of the iso-likelihood region to the volume of the containing
ellipsoid. Unfortunately, in high dimensions the containing ellipsoid
is likely to have a far, far greater volume. This is because the
volume of a high-dimensional ellipsoid is <em>very</em> concentrated <em>very</em>
close to its surface. And this is exactly the region likely to be
within the containing ellipsoid but outside the actual iso-likelihood
region.</p>
<p>On the other hand there’s no guarantee that the iso-likelihood surface
is completely enclosed by the ellipsoid, and if it isn’t, the
calculated evidence will be biased. The <code class="docutils literal notranslate"><span class="pre">enlarge</span></code> parameter (default
1.2) enlarges the ellipsoid by some factor (default 1.2), in the hopes
that the enlarged ellipsoid completely encloses the surface. In
practice this works pretty well for up to tens of parameters. For
larger numbers of parameters, it is probably better to use the
<code class="docutils literal notranslate"><span class="pre">'classic'</span></code> method with a large number of steps.</p>
<p><strong>So how many dimensions can my problem have?</strong></p>
<p>Very roughly, the answer is “tens” and not “hundreds”. However I
haven’t done any exhaustive studies of bias in high dimensions.</p>
<p><strong>How many active points should I use?</strong></p>
<p>It depends. The number of points primarily affects the numerical
accuracy of the results, but there are a couple other
considerations. For the ellipsoid-based methods, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ndim</span> <span class="pre">+</span> <span class="pre">1</span></code> is the
absolute minimum number of points necessary to characterize an
ellipsoid but this will give quite poor estimates. A warning is raised
if the number of points is less than <code class="xref py py-obj docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">ndim</span></code>. Ideally you will have
at least several times more than this. For problems with just a few
parameters (&lt;=5), I get good enough results with just 100 points. If
the posterior is likely to be multi-modal and you’re using the
<code class="xref py py-obj docutils literal notranslate"><span class="pre">'multi'</span></code> method, you will want additional points in order to
characterize each mode well.</p>
<p><strong>What are the differences between the ‘multi’ method and MultiNest?</strong></p>
<p>First, the multi-ellipsoid method in Nestle is based on the algorithm
described in Feroz, Hobson &amp; Bridges (2009), so it doesn’t yet include
any later algorithmic improvements in the MultiNest software. Second,
there are subtle but important differences in the part of the
algorithm that decides when to split an ellipsoid into multiple
ellipsoids. I found that implementing the algorithm precisely as
described gave biased results in higher dimensions due to the
ellipsoids being split too aggressively into a large number of very
small ellipsoids that no longer enclose the full iso-likelihood
surface. Therefore, the implementation in Nestle is more conservative
about splitting ellipsoids. This results in a slightly lower
efficiency but greater robustness.</p>
<p><strong>Sampling is taking a long time. What should I do?</strong></p>
<p>First, you can check the progress by passing the parameter
<code class="docutils literal notranslate"><span class="pre">callback=nestle.print_progress</span></code> to see how sampling is progressing.</p>
<p>If you see the progress in iterations slowing down as sampling
progresses, your likelihood may be multimodal. The default method is
the single ellipsoid method (<code class="docutils literal notranslate"><span class="pre">'single'</span></code>). When the likelihood is
multimodal a single ellipsoid encompassing all active points will
include the “valleys” in the posterior, and sampling from the single
ellipsoid will therefore be inefficient for selecting points higher
than the likelihood constraint. In this case try <code class="docutils literal notranslate"><span class="pre">method='multi'</span></code>.</p>
<p>If sampling seems to be progressing efficiently, it might be the case
that the high likelihood regions of the parameter space are very small
compared to the prior volume. Nested sampling starts by uniformly
sampling the entire prior volume. Then, on each iteration the volume
sampled by the active points shrinks by a constant factor. Thus, the
number of iterations necessary increases as the high-likelihood region
becomes smaller relative to the prior volume. It is important to
consider whether your priors are well-motivated and whether they might
be overly conservatively wide. (Note that an overly conservative prior
will also decrease the evidence!)</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading"></a></h2>
<p>Feroz, Hobson &amp; Bridges 2009. MultiNest: an efficient and robust
Bayesian inference tool for cosmology and particle physics. <em>MNRAS</em>,
<strong>398</strong>, <a class="reference external" href="http://adsabs.harvard.edu/abs/2009MNRAS.398.1601F">1601</a>.</p>
<p>Mukherjee, Parkinson &amp; Liddle 2006. A Nested sampling algorithm for
cosmological model selection. <em>ApJ</em>, <strong>638</strong>, <a class="reference external" href="http://adsabs.harvard.edu/abs/2006ApJ...638L..51M">L51</a>.</p>
<p>Shaw, Bridges &amp; Hobson 2007. Efficient Bayesian inference for
multimodal problems in cosmology. <em>MNRAS</em>, <strong>378</strong>, <a class="reference external" href="http://adsabs.harvard.edu/abs/2007MNRAS.378.1365S">1365</a>.</p>
<p>Silvia &amp; Skilling 2006. Data Analysis: A Bayesian Tutorial, 2nd
Edition. Oxford University Press.</p>
<p>Skilling, J. 2004. Nested Sampling. In <em>Maximum entropy and Bayesian
methods in science and engineering</em> (ed. G. Erickson, J.T. Rychert,
C.R. Smith). <em>AIP Conf. Proc.</em>, <strong>735</strong>,
<a class="reference external" href="http://adsabs.harvard.edu/abs/2004AIPC..735..395S">395</a>.</p>
<p>See also <a class="reference external" href="http://www.inference.phy.cam.ac.uk/bayesys/">http://www.inference.phy.cam.ac.uk/bayesys/</a>.</p>
</section>
<section id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Link to this heading"></a></h2>
<p>If you use Nestle in your work, please cite the github repository and the
relevant references listed above.</p>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="examples/index.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2014-2025, Kyle Barbary and contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>